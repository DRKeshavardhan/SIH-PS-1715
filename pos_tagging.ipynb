{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'VERB', 'NOUN', 'ADV']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc1=nlp('kavi play cricket everyday')\n",
    "s=[]\n",
    "for token in doc1:\n",
    "    s.append(token.pos_)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN', 'VERB', 'NOUN', 'ADV']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: fox\n",
      "Verb: jumps\n",
      "Object: dog\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the pre-trained English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_svo(doc):\n",
    "    subject = None\n",
    "    verb = None\n",
    "    obj = None\n",
    "\n",
    "    for token in doc:\n",
    "        # Check for subject\n",
    "        if \"subj\" in token.dep_:\n",
    "            subject = token.text\n",
    "        \n",
    "        # Check for verb\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verb = token.text\n",
    "        \n",
    "        # Check for object\n",
    "        if \"obj\" in token.dep_:\n",
    "            obj = token.text\n",
    "\n",
    "    return subject, verb, obj\n",
    "\n",
    "# Process the sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "doc = nlp(sentence)\n",
    "subject, verb, obj = extract_svo(doc)\n",
    "\n",
    "print(\"Subject:\", subject)\n",
    "print(\"Verb:\", verb)\n",
    "print(\"Object:\", obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOV Sentence: fox dog jumps.\n",
      "SOV Sentence: fox dog jumps.\n"
     ]
    }
   ],
   "source": [
    "def rephrase_sov(subject, obj, verb):\n",
    "    if subject and obj and verb:\n",
    "        return f\"{subject} {obj} {verb}.\"\n",
    "    else:\n",
    "        return \"Incomplete sentence for SOV conversion.\"\n",
    "\n",
    "sov_sentence = rephrase_sov(subject, obj, verb)\n",
    "print(\"SOV Sentence:\", sov_sentence)\n",
    "def rephrase_sov(subject, obj, verb):\n",
    "    if subject and obj and verb:\n",
    "        return f\"{subject} {obj} {verb}.\"\n",
    "    else:\n",
    "        return \"Incomplete sentence for SOV conversion.\"\n",
    "\n",
    "sov_sentence = rephrase_sov(subject, obj, verb)\n",
    "print(\"SOV Sentence:\", sov_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿MEMBERSHIP PARLIAMENT SEE MINUTE\\n</td>\n",
       "      <td>﻿membership of parliament see minutes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE\\n</td>\n",
       "      <td>approval of minutes of previous sitting see mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEMBERSHIP PARLIAMENT SEE MINUTE\\n</td>\n",
       "      <td>membership of parliament see minutes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VERIFICATION CREDENTIALS SEE MINUTE\\n</td>\n",
       "      <td>verification of credentials see minutes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCUMENT RECEIVE SEE MINUTE\\n</td>\n",
       "      <td>documents received see minutes\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gloss  \\\n",
       "0             ﻿MEMBERSHIP PARLIAMENT SEE MINUTE\\n   \n",
       "1  APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE\\n   \n",
       "2              MEMBERSHIP PARLIAMENT SEE MINUTE\\n   \n",
       "3           VERIFICATION CREDENTIALS SEE MINUTE\\n   \n",
       "4                   DOCUMENT RECEIVE SEE MINUTE\\n   \n",
       "\n",
       "                                                text  \n",
       "0            ﻿membership of parliament see minutes\\n  \n",
       "1  approval of minutes of previous sitting see mi...  \n",
       "2             membership of parliament see minutes\\n  \n",
       "3          verification of credentials see minutes\\n  \n",
       "4                   documents received see minutes\\n  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87710"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87710 entries, 0 to 87709\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   gloss   87710 non-null  object\n",
      " 1   text    87710 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿MEMBERSHIP PARLIAMENT SEE MINUTE\\n</td>\n",
       "      <td>﻿membership of parliament see minutes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE\\n</td>\n",
       "      <td>approval of minutes of previous sitting see mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEMBERSHIP PARLIAMENT SEE MINUTE\\n</td>\n",
       "      <td>membership of parliament see minutes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VERIFICATION CREDENTIALS SEE MINUTE\\n</td>\n",
       "      <td>verification of credentials see minutes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCUMENT RECEIVE SEE MINUTE\\n</td>\n",
       "      <td>documents received see minutes\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gloss  \\\n",
       "0             ﻿MEMBERSHIP PARLIAMENT SEE MINUTE\\n   \n",
       "1  APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE\\n   \n",
       "2              MEMBERSHIP PARLIAMENT SEE MINUTE\\n   \n",
       "3           VERIFICATION CREDENTIALS SEE MINUTE\\n   \n",
       "4                   DOCUMENT RECEIVE SEE MINUTE\\n   \n",
       "\n",
       "                                                text  \n",
       "0            ﻿membership of parliament see minutes\\n  \n",
       "1  approval of minutes of previous sitting see mi...  \n",
       "2             membership of parliament see minutes\\n  \n",
       "3          verification of credentials see minutes\\n  \n",
       "4                   documents received see minutes\\n  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna(axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿MEMBERSHIP PARLIAMENT SEE MINUTE</td>\n",
       "      <td>﻿membership of parliament see minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE</td>\n",
       "      <td>approval of minutes of previous sitting see mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEMBERSHIP PARLIAMENT SEE MINUTE</td>\n",
       "      <td>membership of parliament see minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VERIFICATION CREDENTIALS SEE MINUTE</td>\n",
       "      <td>verification of credentials see minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCUMENT RECEIVE SEE MINUTE</td>\n",
       "      <td>documents received see minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gloss  \\\n",
       "0             ﻿MEMBERSHIP PARLIAMENT SEE MINUTE   \n",
       "1  APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE   \n",
       "2              MEMBERSHIP PARLIAMENT SEE MINUTE   \n",
       "3           VERIFICATION CREDENTIALS SEE MINUTE   \n",
       "4                   DOCUMENT RECEIVE SEE MINUTE   \n",
       "\n",
       "                                                text  \n",
       "0              ﻿membership of parliament see minutes  \n",
       "1  approval of minutes of previous sitting see mi...  \n",
       "2               membership of parliament see minutes  \n",
       "3            verification of credentials see minutes  \n",
       "4                     documents received see minutes  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gloss']=data['gloss'].apply(lambda x: x.strip())\n",
    "data['text']=data['text'].apply(lambda x: x.strip())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['text']\n",
    "y=data['gloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(y, X, train_size=0.08, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vec.toarray())\n",
    "X_test_scaled = scaler.transform(X_test_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2058695652173913\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['even without the financial crisis , these issues are difficult to deal with .']\n"
     ]
    }
   ],
   "source": [
    "X_new_data = \"HOW DEAL difficult sitation\"\n",
    "X_new_data_vec = vectorizer.transform([X_new_data])\n",
    "X_new_data_scaled = scaler.transform(X_new_data_vec.toarray())\n",
    "y_pred = model.predict(X_new_data_scaled)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Vasantha Raj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Vasantha\n",
      "[nltk_data]     Raj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Vasantha\n",
      "[nltk_data]     Raj\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I want to go to chennai\n",
      "Converted: I  go chennai want\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import inflect\n",
    "\n",
    "# Uncomment these lines if you're running for the first time\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and inflect engine\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "p = inflect.engine()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN\n",
    "\n",
    "def convert_svo_to_sov(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = pos_tag(tokens)\n",
    "\n",
    "    subject = None\n",
    "    verb = None\n",
    "    verb_auxiliary = []\n",
    "    objects = []\n",
    "    modifiers = []\n",
    "    prepositions = []\n",
    "    temporal_phrases = []\n",
    "    punctuation = []\n",
    "\n",
    "    def is_pronoun_or_proper_noun(tag):\n",
    "        return tag in ['PRP', 'PRP$', 'NNP', 'NNPS']\n",
    "\n",
    "    for word, tag in tagged:\n",
    "        wn_pos = get_wordnet_pos(tag)\n",
    "\n",
    "        if tag in ['DT', 'IN', 'CC']:  \n",
    "            if prepositions:\n",
    "                prepositions.append(word)\n",
    "            else:\n",
    "                objects.append(word)\n",
    "        elif tag.startswith('VB'):  \n",
    "            if verb is None:\n",
    "                verb = word\n",
    "            else:\n",
    "                verb_auxiliary.append(word)\n",
    "        elif tag.startswith('JJ') or tag.startswith('RB'):  \n",
    "            modifiers.append(word)\n",
    "        elif is_pronoun_or_proper_noun(tag):  \n",
    "            if not subject:\n",
    "                subject = word\n",
    "            else:\n",
    "                objects.append(word)\n",
    "        elif tag in ['NN', 'NNS', 'NNP', 'NNPS']:  \n",
    "            if not subject:\n",
    "                subject = word\n",
    "            else:\n",
    "                objects.append(word)\n",
    "        elif tag == '.':\n",
    "            punctuation.append(word)\n",
    "        elif tag in [',', ':', ';']:\n",
    "            punctuation.append(word)\n",
    "        elif tag == 'PRP$':\n",
    "            modifiers.append(word)\n",
    "\n",
    "    if verb:\n",
    "        verb_base = lemmatizer.lemmatize(verb, wn.VERB)\n",
    "    else:\n",
    "        return \"Unable to convert the sentence: No verb found.\"\n",
    "\n",
    "    object_phrase = \" \".join(objects)  \n",
    "    auxiliary_phrase = \" \".join(verb_auxiliary) if verb_auxiliary else \"\"\n",
    "\n",
    "    if auxiliary_phrase:\n",
    "        full_verb_phrase = f\"{auxiliary_phrase} {verb_base}\"\n",
    "    else:\n",
    "        if verb != verb_base:\n",
    "            full_verb_phrase = f\"did {verb_base}\"\n",
    "        else:\n",
    "            full_verb_phrase = f\"{verb_base}\"\n",
    "\n",
    "    if modifiers:\n",
    "        modifier_phrase = \" \".join(modifiers)\n",
    "    else:\n",
    "        modifier_phrase = \"\"\n",
    "\n",
    "    if temporal_phrases:\n",
    "        temporal_phrase = \" \".join(temporal_phrases)\n",
    "    else:\n",
    "        temporal_phrase = \"\"\n",
    "\n",
    "    if prepositions:\n",
    "        preposition_phrase = \" \".join(prepositions)\n",
    "    else:\n",
    "        preposition_phrase = \"\"\n",
    "\n",
    "    result = f\"{subject} {object_phrase} {modifier_phrase} {preposition_phrase} {full_verb_phrase}\"\n",
    "    result = result.replace(\"  \", \" \").strip()\n",
    "    \n",
    "    # Reattach punctuation to the end\n",
    "    if punctuation:\n",
    "        result += \" \" + \" \".join(punctuation)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the function with additional examples\n",
    "sentences = [\n",
    "    \"I want to go to chennai\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    converted_sentence = convert_svo_to_sov(sentence)\n",
    "    print(f\"Original: {sentence}\")\n",
    "    print(f\"Converted: {converted_sentence}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Obtaining dependency information for inflect from https://files.pythonhosted.org/packages/f7/e0/c5684d7c058d8f2a9210c322dee32bd025c11d19e5ba23c82ac9188253f9/inflect-7.4.0-py3-none-any.whl.metadata\n",
      "  Downloading inflect-7.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: more-itertools>=8.5.0 in c:\\users\\vasantha raj\\anaconda3\\lib\\site-packages (from inflect) (10.1.0)\n",
      "Collecting typeguard>=4.0.1 (from inflect)\n",
      "  Obtaining dependency information for typeguard>=4.0.1 from https://files.pythonhosted.org/packages/eb/de/be0ba39ee73760bf33329b7c6f95bc67e96593c69c881671e312538e24bb/typeguard-4.3.0-py3-none-any.whl.metadata\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vasantha raj\\anaconda3\\lib\\site-packages (from typeguard>=4.0.1->inflect) (4.10.0)\n",
      "Downloading inflect-7.4.0-py3-none-any.whl (34 kB)\n",
      "Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: typeguard, inflect\n",
      "Successfully installed inflect-7.4.0 typeguard-4.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install inflect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
